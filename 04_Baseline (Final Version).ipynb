{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm, trange\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Audio Synchronization Baseline\n",
    "### 1.1 Get chroma features from midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synth_midi_path = 'synth_midi'\n",
    "midi_path = 'midi'\n",
    "piece = 'debussy_childrencorner6'\n",
    "midi_file1 = synth_midi_path + '/sharpeye/' + piece + '_v1.mid'\n",
    "midi_file2 = midi_path + '/' + piece + '.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "hop_size = 0.025\n",
    "window_len = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mid1 = pretty_midi.PrettyMIDI(midi_file1)\n",
    "mid2 = pretty_midi.PrettyMIDI(midi_file2)\n",
    "audio1 = mid1.synthesize()\n",
    "audio2 = mid2.synthesize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chroma1 = librosa.feature.mfcc(audio1, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))\n",
    "chroma2 = librosa.feature.mfcc(audio2, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 DTW on chroma feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alignAudio(M1, M2):\n",
    "    # Get cost metric\n",
    "    C = cdist(M1, M2, 'seuclidean', V=None)\n",
    "    \n",
    "    # DTW\n",
    "    steps = np.array([1,1,1,2,2,1]).reshape((3,2))\n",
    "    weights = np.array([2,3,3])\n",
    "    D, wp = librosa.core.dtw(C=C, step_sizes_sigma=steps, weights_mul=weights)\n",
    "    return wp[::-1,:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wp = alignAudio(np.transpose(chroma1), np.transpose(chroma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Calculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMidiRefLocs(annot_file):\n",
    "    \n",
    "    timeStamps = []\n",
    "    with open(annot_file, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            if row[0] != '-':\n",
    "                timeStamps.append(float(row[0]))\n",
    "            else:\n",
    "                timeStamps.append(float('inf'))\n",
    "    timeStamps = np.array(timeStamps)\n",
    "    \n",
    "    return timeStamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSheetRefLocs(scoreid, changeDPI = False):\n",
    "    \n",
    "    hyp_file = 'hyp_align/'+scoreid+'.pkl'\n",
    "    dhyp = pickle.load(open(hyp_file, 'rb'))\n",
    "    striplens = dhyp['striplens']\n",
    "    \n",
    "    # get annotation file\n",
    "    annot_dir = 'annot_data'\n",
    "    piece = scoreid.split('_')\n",
    "    annot_file_beats = '%s/%s_%s_beats.csv' % (annot_dir, piece[0], piece[1])\n",
    "    df_all = pd.read_csv(annot_file_beats)\n",
    "    \n",
    "    # calculate global pixel position\n",
    "    scoreid = piece[1]+'_'+piece[2]\n",
    "    df = df_all.loc[df_all.score == scoreid]\n",
    "    pixelOffset = np.cumsum([0] + striplens)  # cumulative pixel offset for each strip\n",
    "    stripsPerPage = [df.loc[df.page == i,'strip'].max() for i in range(df.page.max()+1) ]\n",
    "    stripOffset = np.cumsum([0] + stripsPerPage)\n",
    "    stripIdx = stripOffset[df.page] + df.strip - 1  # cumulative strip index\n",
    "    \n",
    "    if changeDPI:\n",
    "        hpixlocs = pixelOffset[stripIdx] + (df.hpixel  * 400 // (72*4))\n",
    "    else:\n",
    "        hpixlocs = pixelOffset[stripIdx] + df.hpixel\n",
    "    \n",
    "    return hpixlocs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synth_timestamps = mid1.get_beats()\n",
    "perf_timestamps1 = mid2.get_beats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcPredErrors(wp, perf_timestamps, synth_timestamps):\n",
    "    all_errs = []    \n",
    "    for i, beat_time in enumerate(perf_timestamps):\n",
    "        frame_id2 = beat_time // hop_size\n",
    "        wp_id2 = np.argmin([abs(x-frame_id2) for x in wp[1]])\n",
    "        frame_id1 = wp[0][wp_id2]\n",
    "        all_errs.append((synth_timestamps[i] - (hop_size*frame_id1)) * 1000) # in ms\n",
    "    return all_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcErrorStats(errs_raw, tols, isSingle = False):\n",
    "    if isSingle:\n",
    "        errs = errs_raw\n",
    "    else:\n",
    "        errs = np.array([err for sublist in errs_raw for err in sublist])\n",
    "    errs = errs[~np.isnan(errs)] # when beat is not annotated, value is nan\n",
    "    errorRates = []\n",
    "    for tol in tols:\n",
    "        toAdd = np.sum(np.abs(errs) > tol) * 1.0 / len(errs)\n",
    "        errorRates.append(toAdd)\n",
    "    return errorRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errs1 = calcPredErrors(wp, perf_timestamps1, synth_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tols = np.arange(5000)\n",
    "errorRates1 = calcErrorStats(errs1, tols, True)\n",
    "plt.plot(tols, 100.0*np.array(errorRates1), 'k-', label='auto-annot')\n",
    "plt.xlabel('Error Tolerance (milliseconds)')\n",
    "plt.ylabel('Error Rate (%)')\n",
    "plt.gca().set_ylim([0,100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Run experiment on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synth_midi_path = 'synth_midi/'\n",
    "midi_path = 'midi/'\n",
    "annot_dir = 'annot_data/'\n",
    "pieces = ['brahms_op116no6', 'brahms_op117no2', \n",
    "          'chopin_op30no2', 'chopin_op63no3', 'chopin_op68no3', \n",
    "          'clementi_op36no1mv3', 'clementi_op36no2mv3', 'clementi_op36no3mv3',\n",
    "          'debussy_childrencorner1', 'debussy_childrencorner3', 'debussy_childrencorner6',\n",
    "          'mendelssohn_op19no2', 'mendelssohn_op62no3', 'mendelssohn_op62no5',\n",
    "          'mozart_kv311mv3', 'mozart_kv333mv3',\n",
    "          'schubert_op90no1', 'schubert_op90no3', 'schubert_op94no2',\n",
    "          'tchaikovsky_season01', 'tchaikovsky_season06', 'tchaikovsky_season08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSingleError(mid_pair, perf_timestamps, synth_timestamps):\n",
    "    mid1 = mid_pair[0]\n",
    "    mid2 = mid_pair[1]\n",
    "    audio1 = mid1.synthesize()\n",
    "    audio2 = mid2.synthesize()\n",
    "    chroma1 = librosa.feature.mfcc(audio1, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))\n",
    "    chroma2 = librosa.feature.mfcc(audio2, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))\n",
    "    wp = alignAudio(np.transpose(chroma1), np.transpose(chroma2))\n",
    "    \n",
    "    if len(synth_timestamps) != len(perf_timestamps):\n",
    "        minLen = min(len(synth_timestamps), len(perf_timestamps))\n",
    "        synth_timestamps = synth_timestamps[:minLen]\n",
    "        perf_timestamps = perf_timestamps[:minLen]\n",
    "        \n",
    "    errs = calcPredErrors(wp, perf_timestamps, synth_timestamps)\n",
    "    return errs, wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runExperiment(program, pieces_list):\n",
    "    allErrs_time = []\n",
    "    allErrs_pixel = []\n",
    "    \n",
    "    for piece in pieces_list:\n",
    "        all_sheets = sorted(glob.glob('score_data/prepped_pdf/%s*' % piece))\n",
    "        real_midis = sorted(glob.glob(midi_path+'%s*' % piece))\n",
    "        perf_timestamps = getMidiRefLocs(annot_dir + 'midi/' + piece + '.csv')\n",
    "        \n",
    "        if program == 'sharpeye':\n",
    "            synth_annot_files = sorted(glob.glob(annot_dir+'synth_midi/'+'%s*_se.csv' % piece.split('_')[1]))\n",
    "        elif program == 'photoscore':\n",
    "            synth_annot_files = sorted(glob.glob(annot_dir+'synth_midi/'+'%s*_ps.csv' % piece.split('_')[1]))\n",
    "        \n",
    "        for i in range(len(real_midis)):\n",
    "            mid2 = pretty_midi.PrettyMIDI(real_midis[i])\n",
    "            \n",
    "            for j in range(len(all_sheets)):\n",
    "                scoreid = all_sheets[j].split('/')[-1].split('.')[0]\n",
    "                sheet_annot = getSheetRefLocs(scoreid)\n",
    "                synth_file = synth_midi_path+program+'/'+scoreid+'.mid'\n",
    "                synth_name = synth_file.split('/')[-1].split('.')[0]\n",
    "                synth_name = synth_name.split('_')[1] + '_' + synth_name.split('_')[2]\n",
    "                    \n",
    "                if program == 'sharpeye':\n",
    "                    synth_annot_file = annot_dir + 'synth_midi/' + synth_name + '_se.csv'\n",
    "                elif program == 'photoscore':\n",
    "                    synth_annot_file = annot_dir + 'synth_midi/' + synth_name + '_ps.csv'\n",
    "                        \n",
    "                if synth_annot_file in synth_annot_files and (program != 'photoscore' or scoreid != 'chopin_op68no3_v6'):\n",
    "                    mid1 = pretty_midi.PrettyMIDI(synth_file)\n",
    "                    print(real_midis[i], synth_file)\n",
    "                \n",
    "                    synth_timestamps = getMidiRefLocs(synth_annot_file)\n",
    "                    err_t, wp = calcSingleError([mid1, mid2], perf_timestamps, synth_timestamps)\n",
    "                    allErrs_time.append(err_t)\n",
    "                    \n",
    "                    hypPixels = np.interp(perf_timestamps, wp[:,1], wp[:,0])\n",
    "                    minLen_p = min(len(hypPixels), len(sheet_annot))\n",
    "                    allErrs_pixel.append(hypPixels[:minLen_p] - sheet_annot[:minLen_p])\n",
    "                    \n",
    "                else:\n",
    "                    allErrs_pixel.append([float('inf')]*len(sheet_annot))\n",
    "                    allErrs_time.append([float('inf')]*len(perf_timestamps))\n",
    "        \n",
    "    return allErrs_pixel, allErrs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alignAll(program, pieces_list):\n",
    "    allwp = {}\n",
    "    \n",
    "    for piece in pieces_list:\n",
    "        synth_midis = [os.path.basename(elem) for elem in sorted(glob.glob(synth_midi_path+program+'/%s*' % piece))]\n",
    "        real_midis = [os.path.basename(elem) for elem in sorted(glob.glob(midi_path+'/*%s*' % piece))]\n",
    "        \n",
    "        for i in trange(len(real_midis)):\n",
    "            real_midi_name = real_midis[i]\n",
    "            #real_full_path = midi_path + '/' + piece + '/' + real_midi_name\n",
    "            real_full_path = midi_path + '/' + real_midi_name\n",
    "            mid2 = pretty_midi.PrettyMIDI(real_full_path)\n",
    "            audio2 = mid2.synthesize()\n",
    "            chroma2 = librosa.feature.mfcc(audio2, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))\n",
    "            \n",
    "            for j in range(len(synth_midis)):\n",
    "                synth_midi_name = synth_midis[j]\n",
    "                synth_full_path = synth_midi_path+'/'+program+'/'+synth_midi_name\n",
    "                \n",
    "                mid1 = pretty_midi.PrettyMIDI(synth_full_path)\n",
    "                audio1 = mid1.synthesize()\n",
    "                chroma1 = librosa.feature.mfcc(audio1, sr, hop_length=int(hop_size*sr), n_fft=int(window_len*sr))\n",
    "                \n",
    "                wp = alignAudio(np.transpose(chroma1), np.transpose(chroma2))\n",
    "                \n",
    "                allwp[(real_full_path, synth_full_path)] = wp\n",
    "                \n",
    "    with open('results/audioalign_nonmzk_'+program+'.pkl','wb') as f:\n",
    "        pickle.dump(allwp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignAll('photoscore', pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignAll('sharpeye', pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allErrs_se_as_pix, allErrs_se_as_t = runExperiment('sharpeye', pieces)\n",
    "allErrs_ps_as_pix, allErrs_ps_as_t = runExperiment('photoscore', pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results/errorData_real_as.pkl','wb') as f:\n",
    "    pickle.dump([allErrs_ps_as_pix, allErrs_ps_as_t, allErrs_se_as_pix, allErrs_se_as_t],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Midi-Beat-Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def midiBeatMatch(program, pieces_list):\n",
    "    allErrs_pixel = []\n",
    "    allErrs_time = []\n",
    "    \n",
    "    for piece in pieces_list:\n",
    "        perf_timestamps = getMidiRefLocs(annot_dir + 'midi/' + piece + '.csv')\n",
    "        all_sheets = sorted(glob.glob('score_data/prepped_pdf/%s*' % piece))\n",
    "        if program == 'sharpeye':\n",
    "            synth_annot_files = sorted(glob.glob(annot_dir+'synth_midi/'+'%s*_se.csv' % piece.split('_')[1]))\n",
    "        elif program == 'photoscore':\n",
    "            synth_annot_files = sorted(glob.glob(annot_dir+'synth_midi/'+'%s*_ps.csv' % piece.split('_')[1]))\n",
    "        print(synth_annot_files)\n",
    "            \n",
    "        for j in range(len(all_sheets)):\n",
    "            scoreid = all_sheets[j].split('/')[-1].split('.')[0]\n",
    "            sheet_annot = getSheetRefLocs(scoreid)\n",
    "            synth_file = synth_midi_path+program+'/'+scoreid+'.mid'\n",
    "            \n",
    "            synth_name = synth_file.split('/')[-1].split('.')[0]\n",
    "            synth_name = synth_name.split('_')[1] + '_' + synth_name.split('_')[2]\n",
    "            \n",
    "            if program == 'sharpeye':\n",
    "                synth_annot_file = annot_dir + 'synth_midi/' + synth_name + '_se.csv'\n",
    "            elif program == 'photoscore':\n",
    "                synth_annot_file = annot_dir + 'synth_midi/' + synth_name + '_ps.csv'\n",
    "            print(synth_annot_file)\n",
    "            \n",
    "            if synth_annot_file in synth_annot_files and (program != 'photoscore' or scoreid != 'chopin_op68no3_v6'):\n",
    "                mid1 = pretty_midi.PrettyMIDI(synth_file)\n",
    "                start_time = mid1.estimate_beat_start(candidates=10, tolerance=0.025)\n",
    "                auto_beat = mid1.get_beats()\n",
    "                \n",
    "                synth_timestamps = getMidiRefLocs(synth_annot_file)\n",
    "                \n",
    "                print(auto_beat[0:10])\n",
    "                print(synth_timestamps[0:10])\n",
    "                \n",
    "                minLen_t = min(len(synth_timestamps), len(auto_beat))\n",
    "                allErrs_time.append((np.array(synth_timestamps[:minLen_t]) - np.array(auto_beat[:minLen_t])) * 1000)\n",
    "                \n",
    "                minLen_p = min(minLen_t, len(sheet_annot))\n",
    "                hypPixels = np.interp(auto_beat, synth_timestamps[:minLen_p], sheet_annot[:minLen_p])\n",
    "                allErrs_pixel.append(hypPixels[:minLen_p] - sheet_annot[:minLen_p])\n",
    "            \n",
    "            else:\n",
    "                allErrs_pixel.append([float('inf')*len(sheet_annot)])\n",
    "                allErrs_time.append([float('inf')]*len(perf_timestamps))\n",
    "                \n",
    "    return allErrs_pixel, allErrs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allErrs_se_bm_pix, allErrs_se_bm_t = midiBeatMatch('sharpeye', pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allErrs_ps_bm_pix, allErrs_ps_bm_t = midiBeatMatch('photoscore', pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results/errorData_real_bm.pkl','wb') as f:\n",
    "    pickle.dump([allErrs_ps_bm_pix, allErrs_ps_bm_t, allErrs_se_bm_pix, allErrs_se_bm_t],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Error to Bootleg System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[allErrs_ps_bm_pix, allErrs_ps_bm_t, allErrs_se_bm_pix, allErrs_se_bm_t] = pickle.load(open('results/errorData_real_bm.pkl', 'rb'))\n",
    "[pixel_errs_bs, pixel_errs_b1, time_errs_bs, time_errs_b1] = pickle.load(open('results/errorData_real_bootleg.pkl', 'rb'))\n",
    "[allErrs_ps_as_pix, allErrs_ps_as_t, allErrs_se_as_pix, allErrs_se_as_t] = pickle.load(open('results/errorData_real_as.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tols = np.arange(2001)\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(time_errs_b1, tols)), 'k-', label='GL')\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(allErrs_se_bm_t, tols)), 'g-.', label='MBM-se')\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(allErrs_ps_bm_t, tols)), 'r-.', label='MBM-ps')\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(allErrs_se_as_t, tols)), 'g--', label='AS-se')\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(allErrs_ps_as_t, tols)), 'r--', label='AS-ps')\n",
    "plt.plot(tols, 100.0*np.array(calcErrorStats(time_errs_bs, tols)), 'g-', label='BS')\n",
    "\n",
    "plt.xlabel('Error Tolerance (milliseconds)')\n",
    "plt.ylabel('Error Rate (%)')\n",
    "plt.gca().set_ylim([0,100])\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.savefig('figs/error_curves(final).png', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
